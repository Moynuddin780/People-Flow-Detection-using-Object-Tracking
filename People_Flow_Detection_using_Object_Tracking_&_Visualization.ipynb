{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# People Flow Detection using Object Tracking Visualization\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“‹ Overview\n",
        "This project implements a sophisticated system to detect and count people entering and exiting a defined area in a video using object tracking and heatmap visualization. It leverages **YOLOv8** for detection and **ByteTrack** for tracking, complemented by a heatmap to illustrate movement intensity. Bounding boxes are drawn in green with unique track IDs for clear identification.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ” Detection Method\n",
        "- **Model**: YOLOv8 (pre-trained `yolov8n.pt`) for detecting persons (class 0).\n",
        "- **Tracker**: ByteTrack ensures consistent tracking of individuals across frames.\n",
        "- **Libraries**: Utilizes OpenCV, Ultralytics YOLO, Supervision, and Matplotlib for processing and visualization.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“ Line Coordinates\n",
        "- **Upper Line (IN)**: Positioned at `y = frame height / 3`, marked in **blue**.\n",
        "- **Lower Line (OUT)**: Positioned at `y = 2 * frame height / 3`, marked in **red**.\n",
        "- Defined using the [PolygonZone](https://polygonzone.roboflow.com/) framework.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§® Logic for IN/OUT Counting\n",
        "- **IN**: A person is counted as entering when their trajectory moves downward, crossing the upper line (y-coordinate transitions from below `LINE_Y1` to at or above `LINE_Y1`).\n",
        "- **OUT**: A person is counted as exiting when their trajectory moves upward, crossing the lower line (y-coordinate transitions from above `LINE_Y2` to at or below `LINE_Y2`).\n",
        "- The system tracks the center y-coordinate of bounding boxes to determine direction, updating counters based on these crossings.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“¤ Output\n",
        "- **Video**: `output_video.mp4` displays bounding boxes, track IDs, color-coded lines, and live IN/OUT counters.\n",
        "- **Heatmap**: `heatmap.png` visualizes movement intensity using bounding box center points, normalized with a 'hot' colormap.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“¥ Input & Output Files\n",
        "- **Input Video**: Paste your video file path here (e.g., `/content/people-walking video.mp4`).\n",
        "- **Output People Flow Detection Video**: Save as `output_video.mp4`.\n",
        "- **Heatmap Image**: Save as `heatmap.png`.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸš€ Setup\n",
        "1. Install required dependencies in your Colab environment:\n",
        "   ```bash\n",
        "   !pip install opencv-python numpy ultralytics supervision matplotlib\n"
      ],
      "metadata": {
        "id": "WUo1fEmnLRKq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "DpucONJmHaps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from supervision import ByteTrack, Color\n",
        "import supervision as sv\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "5ytRSY78Zl_J"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load YOLOv8n model"
      ],
      "metadata": {
        "id": "hhUDjIFuHmtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"yolov8n.pt\")"
      ],
      "metadata": {
        "id": "Ggmf4q5uGHq5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Video input\n"
      ],
      "metadata": {
        "id": "G10jdl7lHwdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = \"/content/people-walking video.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n"
      ],
      "metadata": {
        "id": "Q-iWC_uBGHtu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get video properties\n"
      ],
      "metadata": {
        "id": "zUmZ3UOwH0KT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))"
      ],
      "metadata": {
        "id": "oMFM7FYKGHw5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define two horizontal lines\n"
      ],
      "metadata": {
        "id": "BLGkUbtcH4Rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LINE_Y1 = height // 3  # Upper line\n",
        "LINE_Y2 = 2 * height // 3  # Lower line\n",
        "LINE_COLOR_UP = Color.BLUE\n",
        "LINE_COLOR_DOWN = Color.RED"
      ],
      "metadata": {
        "id": "YK5yOBdJGH5Y"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize counters, tracker, and history\n"
      ],
      "metadata": {
        "id": "AwLDsLl8H8Y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_count = 0\n",
        "out_count = 0\n",
        "tracker = ByteTrack()\n",
        "track_history = {}\n",
        "counted_in_ids = set()\n",
        "counted_out_ids = set()\n",
        "heatmap = np.zeros((height, width), dtype=np.float32)"
      ],
      "metadata": {
        "id": "_N-i57joGH8I"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output video setup\n"
      ],
      "metadata": {
        "id": "tMUk9dNaICki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = \"output_video.mp4\"\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))"
      ],
      "metadata": {
        "id": "jA2HSzE1GH-0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Line coordinates for counting\n"
      ],
      "metadata": {
        "id": "o7FzVehtIGEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "line1 = sv.LineZone(start=sv.Point(0, LINE_Y1), end=sv.Point(width, LINE_Y1))\n",
        "line2 = sv.LineZone(start=sv.Point(0, LINE_Y2), end=sv.Point(width, LINE_Y2))"
      ],
      "metadata": {
        "id": "3icJ7PFLGIBV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Frame processing\n"
      ],
      "metadata": {
        "id": "TyqjKcSptcbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_frame(frame, frame_num):\n",
        "    global in_count, out_count\n",
        "\n",
        "    results = model(frame, classes=[0])[0]\n",
        "    detections = sv.Detections.from_ultralytics(results)\n",
        "    detections = tracker.update_with_detections(detections)\n",
        "\n",
        "    annotated_frame = frame.copy()\n",
        "\n",
        "    for box, track_id in zip(detections.xyxy, detections.tracker_id):\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "        center_x = (x1 + x2) // 2\n",
        "        center_y = (y1 + y2) // 2\n",
        "\n",
        "        # Track history\n",
        "        if track_id not in track_history:\n",
        "            track_history[track_id] = []\n",
        "        track_history[track_id].append((center_x, center_y))\n",
        "\n",
        "        # Count IN/OUT once per person\n",
        "        if len(track_history[track_id]) > 1:\n",
        "            prev_x, prev_y = track_history[track_id][-2]\n",
        "            curr_x, curr_y = track_history[track_id][-1]\n",
        "\n",
        "            # IN\n",
        "            if prev_y < LINE_Y1 and curr_y >= LINE_Y1 and track_id not in counted_in_ids:\n",
        "                in_count += 1\n",
        "                counted_in_ids.add(track_id)\n",
        "\n",
        "            # OUT\n",
        "            elif prev_y > LINE_Y2 and curr_y <= LINE_Y2 and track_id not in counted_out_ids:\n",
        "                out_count += 1\n",
        "                counted_out_ids.add(track_id)\n",
        "\n",
        "        # Draw bounding boxes based on status\n",
        "        if track_id in counted_in_ids:\n",
        "            overlay = annotated_frame.copy()\n",
        "            cv2.rectangle(overlay, (x1, y1), (x2, y2), (0, 255, 0), -1)  # Green overlay\n",
        "            alpha = 0.3\n",
        "            cv2.addWeighted(overlay, alpha, annotated_frame, 1 - alpha, 0, annotated_frame)\n",
        "            cv2.putText(annotated_frame, f\"ID: {track_id}\", (x1, y1 - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "        elif track_id in counted_out_ids:\n",
        "            overlay = annotated_frame.copy()\n",
        "            cv2.rectangle(overlay, (x1, y1), (x2, y2), (0, 0, 255), -1)  # Red overlay\n",
        "            alpha = 0.3\n",
        "            cv2.addWeighted(overlay, alpha, annotated_frame, 1 - alpha, 0, annotated_frame)\n",
        "            cv2.putText(annotated_frame, f\"ID: {track_id}\", (x1, y1 - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
        "\n",
        "        else:\n",
        "            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green\n",
        "            cv2.putText(annotated_frame, f\"ID: {track_id}\", (x1, y1 - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    # Draw IN/OUT lines\n",
        "    cv2.line(annotated_frame, (0, LINE_Y1), (width, LINE_Y1), LINE_COLOR_UP.as_bgr(), 2)\n",
        "    cv2.line(annotated_frame, (0, LINE_Y2), (width, LINE_Y2), LINE_COLOR_DOWN.as_bgr(), 2)\n",
        "\n",
        "    # Draw white trajectory lines\n",
        "    for person_id, points in track_history.items():\n",
        "        if len(points) > 1:\n",
        "            for i in range(1, len(points)):\n",
        "                pt1 = points[i - 1]\n",
        "                pt2 = points[i]\n",
        "                cv2.line(annotated_frame, pt1, pt2, (255, 255, 255), 2)\n",
        "\n",
        "    # Display larger counters\n",
        "    cv2.putText(annotated_frame, f\"IN: {in_count}\", (10, 50),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0, 255, 0), 3)\n",
        "    cv2.putText(annotated_frame, f\"OUT: {out_count}\", (10, 100),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0, 0, 255), 3)\n",
        "\n",
        "    return annotated_frame"
      ],
      "metadata": {
        "id": "JTvFQ2UTtYHT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process video\n"
      ],
      "metadata": {
        "id": "Kss6b3S2IWP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frame_num = 0\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    annotated_frame = process_frame(frame, frame_num)\n",
        "    out.write(annotated_frame)\n",
        "    frame_num += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3yb-yMFGID0",
        "outputId": "299fad57-48a1-485a-dac5-3d04360ca928"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 37 persons, 446.9ms\n",
            "Speed: 26.7ms preprocess, 446.9ms inference, 44.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 188.7ms\n",
            "Speed: 5.4ms preprocess, 188.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 146.3ms\n",
            "Speed: 4.1ms preprocess, 146.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 172.8ms\n",
            "Speed: 30.0ms preprocess, 172.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 153.2ms\n",
            "Speed: 6.6ms preprocess, 153.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 173.1ms\n",
            "Speed: 13.5ms preprocess, 173.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 157.4ms\n",
            "Speed: 8.5ms preprocess, 157.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 163.3ms\n",
            "Speed: 4.3ms preprocess, 163.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 140.0ms\n",
            "Speed: 4.6ms preprocess, 140.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 155.9ms\n",
            "Speed: 4.0ms preprocess, 155.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 144.5ms\n",
            "Speed: 3.9ms preprocess, 144.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 231.2ms\n",
            "Speed: 4.8ms preprocess, 231.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 225.8ms\n",
            "Speed: 7.1ms preprocess, 225.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 213.5ms\n",
            "Speed: 4.5ms preprocess, 213.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 230.5ms\n",
            "Speed: 6.6ms preprocess, 230.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 228.7ms\n",
            "Speed: 5.1ms preprocess, 228.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 211.4ms\n",
            "Speed: 4.1ms preprocess, 211.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 219.8ms\n",
            "Speed: 6.8ms preprocess, 219.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 212.9ms\n",
            "Speed: 12.1ms preprocess, 212.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 227.9ms\n",
            "Speed: 5.9ms preprocess, 227.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 205.0ms\n",
            "Speed: 8.1ms preprocess, 205.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 141.4ms\n",
            "Speed: 4.4ms preprocess, 141.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 150.1ms\n",
            "Speed: 4.0ms preprocess, 150.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 139.3ms\n",
            "Speed: 4.3ms preprocess, 139.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 138.7ms\n",
            "Speed: 4.8ms preprocess, 138.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 137.1ms\n",
            "Speed: 5.6ms preprocess, 137.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 145.2ms\n",
            "Speed: 4.3ms preprocess, 145.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 136.4ms\n",
            "Speed: 4.3ms preprocess, 136.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 140.8ms\n",
            "Speed: 6.0ms preprocess, 140.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 152.7ms\n",
            "Speed: 4.4ms preprocess, 152.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 139.6ms\n",
            "Speed: 4.4ms preprocess, 139.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 136.8ms\n",
            "Speed: 4.6ms preprocess, 136.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 144.7ms\n",
            "Speed: 5.2ms preprocess, 144.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 138.6ms\n",
            "Speed: 4.1ms preprocess, 138.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 155.9ms\n",
            "Speed: 4.3ms preprocess, 155.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 136.9ms\n",
            "Speed: 4.4ms preprocess, 136.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 140.6ms\n",
            "Speed: 4.6ms preprocess, 140.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 133.7ms\n",
            "Speed: 4.3ms preprocess, 133.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 145.0ms\n",
            "Speed: 4.6ms preprocess, 145.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 147.4ms\n",
            "Speed: 4.4ms preprocess, 147.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 141.1ms\n",
            "Speed: 4.3ms preprocess, 141.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 136.8ms\n",
            "Speed: 4.3ms preprocess, 136.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 141.8ms\n",
            "Speed: 5.0ms preprocess, 141.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 139.5ms\n",
            "Speed: 4.5ms preprocess, 139.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 158.9ms\n",
            "Speed: 4.4ms preprocess, 158.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 141.1ms\n",
            "Speed: 4.6ms preprocess, 141.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 142.6ms\n",
            "Speed: 4.5ms preprocess, 142.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 152.7ms\n",
            "Speed: 4.5ms preprocess, 152.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 137.7ms\n",
            "Speed: 4.6ms preprocess, 137.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 152.9ms\n",
            "Speed: 4.5ms preprocess, 152.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 40 persons, 139.1ms\n",
            "Speed: 4.6ms preprocess, 139.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 41 persons, 140.4ms\n",
            "Speed: 4.1ms preprocess, 140.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 140.2ms\n",
            "Speed: 4.4ms preprocess, 140.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 139.9ms\n",
            "Speed: 4.9ms preprocess, 139.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 40 persons, 151.6ms\n",
            "Speed: 4.4ms preprocess, 151.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 152.0ms\n",
            "Speed: 5.4ms preprocess, 152.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 39 persons, 146.0ms\n",
            "Speed: 6.3ms preprocess, 146.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 147.3ms\n",
            "Speed: 4.4ms preprocess, 147.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 136.5ms\n",
            "Speed: 4.3ms preprocess, 136.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 153.7ms\n",
            "Speed: 5.7ms preprocess, 153.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 145.5ms\n",
            "Speed: 4.5ms preprocess, 145.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 39 persons, 143.6ms\n",
            "Speed: 4.5ms preprocess, 143.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 147.9ms\n",
            "Speed: 4.6ms preprocess, 147.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 145.2ms\n",
            "Speed: 4.8ms preprocess, 145.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 155.1ms\n",
            "Speed: 4.4ms preprocess, 155.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 150.4ms\n",
            "Speed: 4.6ms preprocess, 150.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 39 persons, 143.8ms\n",
            "Speed: 4.4ms preprocess, 143.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 141.2ms\n",
            "Speed: 4.9ms preprocess, 141.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 138.3ms\n",
            "Speed: 4.7ms preprocess, 138.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 220.5ms\n",
            "Speed: 4.7ms preprocess, 220.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 39 persons, 210.6ms\n",
            "Speed: 5.0ms preprocess, 210.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 215.3ms\n",
            "Speed: 4.5ms preprocess, 215.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 230.7ms\n",
            "Speed: 4.9ms preprocess, 230.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 41 persons, 211.2ms\n",
            "Speed: 11.4ms preprocess, 211.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 42 persons, 205.4ms\n",
            "Speed: 5.1ms preprocess, 205.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 40 persons, 219.1ms\n",
            "Speed: 5.6ms preprocess, 219.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 41 persons, 218.4ms\n",
            "Speed: 4.7ms preprocess, 218.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 42 persons, 191.9ms\n",
            "Speed: 4.5ms preprocess, 191.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 41 persons, 136.2ms\n",
            "Speed: 4.4ms preprocess, 136.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 40 persons, 155.0ms\n",
            "Speed: 4.3ms preprocess, 155.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 40 persons, 135.0ms\n",
            "Speed: 4.3ms preprocess, 135.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 141.5ms\n",
            "Speed: 4.6ms preprocess, 141.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 41 persons, 143.8ms\n",
            "Speed: 6.0ms preprocess, 143.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 137.3ms\n",
            "Speed: 4.5ms preprocess, 137.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 154.2ms\n",
            "Speed: 4.5ms preprocess, 154.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 142.7ms\n",
            "Speed: 4.2ms preprocess, 142.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 141.0ms\n",
            "Speed: 4.1ms preprocess, 141.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 143.5ms\n",
            "Speed: 4.1ms preprocess, 143.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 150.9ms\n",
            "Speed: 5.4ms preprocess, 150.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 144.1ms\n",
            "Speed: 5.4ms preprocess, 144.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 40 persons, 147.6ms\n",
            "Speed: 4.5ms preprocess, 147.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 165.6ms\n",
            "Speed: 4.4ms preprocess, 165.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 152.4ms\n",
            "Speed: 4.4ms preprocess, 152.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 153.2ms\n",
            "Speed: 4.7ms preprocess, 153.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 136.4ms\n",
            "Speed: 4.8ms preprocess, 136.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 145.5ms\n",
            "Speed: 6.5ms preprocess, 145.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 137.8ms\n",
            "Speed: 4.4ms preprocess, 137.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 153.5ms\n",
            "Speed: 4.4ms preprocess, 153.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 140.2ms\n",
            "Speed: 6.1ms preprocess, 140.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 139.4ms\n",
            "Speed: 4.0ms preprocess, 139.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 144.8ms\n",
            "Speed: 4.4ms preprocess, 144.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 261.1ms\n",
            "Speed: 4.4ms preprocess, 261.1ms inference, 25.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 296.0ms\n",
            "Speed: 4.1ms preprocess, 296.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 273.8ms\n",
            "Speed: 4.1ms preprocess, 273.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 155.0ms\n",
            "Speed: 4.4ms preprocess, 155.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 139.9ms\n",
            "Speed: 4.6ms preprocess, 139.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 152.2ms\n",
            "Speed: 4.7ms preprocess, 152.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 149.5ms\n",
            "Speed: 4.4ms preprocess, 149.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 159.6ms\n",
            "Speed: 4.4ms preprocess, 159.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 140.3ms\n",
            "Speed: 5.0ms preprocess, 140.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 139.0ms\n",
            "Speed: 4.5ms preprocess, 139.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 143.3ms\n",
            "Speed: 4.6ms preprocess, 143.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 139.9ms\n",
            "Speed: 5.4ms preprocess, 139.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 139.6ms\n",
            "Speed: 12.4ms preprocess, 139.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 195.7ms\n",
            "Speed: 4.4ms preprocess, 195.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 248.8ms\n",
            "Speed: 15.2ms preprocess, 248.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 296.0ms\n",
            "Speed: 4.9ms preprocess, 296.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 965.9ms\n",
            "Speed: 14.5ms preprocess, 965.9ms inference, 34.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 585.0ms\n",
            "Speed: 11.0ms preprocess, 585.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 244.8ms\n",
            "Speed: 16.9ms preprocess, 244.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 177.4ms\n",
            "Speed: 4.9ms preprocess, 177.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 141.1ms\n",
            "Speed: 5.6ms preprocess, 141.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 154.8ms\n",
            "Speed: 4.4ms preprocess, 154.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 139.3ms\n",
            "Speed: 3.8ms preprocess, 139.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 37 persons, 152.2ms\n",
            "Speed: 4.3ms preprocess, 152.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 36 persons, 147.7ms\n",
            "Speed: 4.4ms preprocess, 147.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 38 persons, 134.3ms\n",
            "Speed: 6.5ms preprocess, 134.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 138.2ms\n",
            "Speed: 4.1ms preprocess, 138.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 133.6ms\n",
            "Speed: 4.2ms preprocess, 133.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 143.3ms\n",
            "Speed: 4.6ms preprocess, 143.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 141.3ms\n",
            "Speed: 4.3ms preprocess, 141.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 143.3ms\n",
            "Speed: 5.2ms preprocess, 143.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 140.4ms\n",
            "Speed: 4.5ms preprocess, 140.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 155.0ms\n",
            "Speed: 4.4ms preprocess, 155.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 139.5ms\n",
            "Speed: 4.4ms preprocess, 139.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 139.3ms\n",
            "Speed: 4.5ms preprocess, 139.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 136.6ms\n",
            "Speed: 4.1ms preprocess, 136.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 158.0ms\n",
            "Speed: 4.1ms preprocess, 158.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 150.5ms\n",
            "Speed: 4.4ms preprocess, 150.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 139.5ms\n",
            "Speed: 4.4ms preprocess, 139.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 139.6ms\n",
            "Speed: 4.3ms preprocess, 139.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 139.0ms\n",
            "Speed: 6.6ms preprocess, 139.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 146.8ms\n",
            "Speed: 4.7ms preprocess, 146.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 140.8ms\n",
            "Speed: 4.7ms preprocess, 140.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 133.5ms\n",
            "Speed: 4.4ms preprocess, 133.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 135.3ms\n",
            "Speed: 4.6ms preprocess, 135.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 146.2ms\n",
            "Speed: 5.0ms preprocess, 146.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 134.8ms\n",
            "Speed: 4.7ms preprocess, 134.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 131.8ms\n",
            "Speed: 4.6ms preprocess, 131.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 140.2ms\n",
            "Speed: 4.5ms preprocess, 140.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 132.8ms\n",
            "Speed: 5.4ms preprocess, 132.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 140.7ms\n",
            "Speed: 5.3ms preprocess, 140.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 135.6ms\n",
            "Speed: 4.5ms preprocess, 135.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 142.7ms\n",
            "Speed: 4.5ms preprocess, 142.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 140.3ms\n",
            "Speed: 4.6ms preprocess, 140.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 144.4ms\n",
            "Speed: 4.5ms preprocess, 144.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 139.7ms\n",
            "Speed: 4.4ms preprocess, 139.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 141.3ms\n",
            "Speed: 4.8ms preprocess, 141.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 138.0ms\n",
            "Speed: 5.2ms preprocess, 138.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 170.5ms\n",
            "Speed: 4.4ms preprocess, 170.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 153.8ms\n",
            "Speed: 6.5ms preprocess, 153.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 141.3ms\n",
            "Speed: 4.7ms preprocess, 141.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 212.2ms\n",
            "Speed: 8.1ms preprocess, 212.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 207.9ms\n",
            "Speed: 4.2ms preprocess, 207.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 216.1ms\n",
            "Speed: 7.4ms preprocess, 216.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 216.5ms\n",
            "Speed: 9.0ms preprocess, 216.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 210.2ms\n",
            "Speed: 4.4ms preprocess, 210.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 223.8ms\n",
            "Speed: 4.3ms preprocess, 223.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 229.0ms\n",
            "Speed: 12.5ms preprocess, 229.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 220.6ms\n",
            "Speed: 4.9ms preprocess, 220.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 148.3ms\n",
            "Speed: 4.5ms preprocess, 148.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 134.3ms\n",
            "Speed: 4.5ms preprocess, 134.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 147.0ms\n",
            "Speed: 4.0ms preprocess, 147.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 145.5ms\n",
            "Speed: 4.2ms preprocess, 145.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 140.9ms\n",
            "Speed: 4.5ms preprocess, 140.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 138.4ms\n",
            "Speed: 4.8ms preprocess, 138.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 140.0ms\n",
            "Speed: 4.7ms preprocess, 140.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 156.9ms\n",
            "Speed: 5.5ms preprocess, 156.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 142.0ms\n",
            "Speed: 4.5ms preprocess, 142.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 144.0ms\n",
            "Speed: 3.5ms preprocess, 144.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 135.4ms\n",
            "Speed: 4.7ms preprocess, 135.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 154.8ms\n",
            "Speed: 4.3ms preprocess, 154.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 135.1ms\n",
            "Speed: 4.1ms preprocess, 135.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 148.4ms\n",
            "Speed: 6.2ms preprocess, 148.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 136.4ms\n",
            "Speed: 4.0ms preprocess, 136.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 142.7ms\n",
            "Speed: 4.1ms preprocess, 142.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 140.4ms\n",
            "Speed: 5.4ms preprocess, 140.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 143.6ms\n",
            "Speed: 5.8ms preprocess, 143.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 135.7ms\n",
            "Speed: 5.4ms preprocess, 135.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 138.0ms\n",
            "Speed: 4.8ms preprocess, 138.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 151.8ms\n",
            "Speed: 4.8ms preprocess, 151.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 141.0ms\n",
            "Speed: 5.5ms preprocess, 141.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 137.1ms\n",
            "Speed: 4.8ms preprocess, 137.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 137.0ms\n",
            "Speed: 4.5ms preprocess, 137.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 157.6ms\n",
            "Speed: 3.9ms preprocess, 157.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 139.6ms\n",
            "Speed: 4.6ms preprocess, 139.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 146.9ms\n",
            "Speed: 4.6ms preprocess, 146.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 133.4ms\n",
            "Speed: 6.2ms preprocess, 133.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 35 persons, 152.6ms\n",
            "Speed: 4.5ms preprocess, 152.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 133.2ms\n",
            "Speed: 4.4ms preprocess, 133.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 144.6ms\n",
            "Speed: 4.8ms preprocess, 144.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 134.4ms\n",
            "Speed: 6.8ms preprocess, 134.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 154.7ms\n",
            "Speed: 4.1ms preprocess, 154.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 136.9ms\n",
            "Speed: 4.3ms preprocess, 136.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 142.0ms\n",
            "Speed: 4.8ms preprocess, 142.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 134.0ms\n",
            "Speed: 5.0ms preprocess, 134.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 148.2ms\n",
            "Speed: 3.9ms preprocess, 148.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 134.1ms\n",
            "Speed: 4.5ms preprocess, 134.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 141.3ms\n",
            "Speed: 5.0ms preprocess, 141.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 138.4ms\n",
            "Speed: 4.7ms preprocess, 138.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 229.3ms\n",
            "Speed: 4.0ms preprocess, 229.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 207.2ms\n",
            "Speed: 5.6ms preprocess, 207.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 222.6ms\n",
            "Speed: 4.5ms preprocess, 222.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 222.1ms\n",
            "Speed: 4.5ms preprocess, 222.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 208.2ms\n",
            "Speed: 4.3ms preprocess, 208.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 221.1ms\n",
            "Speed: 4.1ms preprocess, 221.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 240.6ms\n",
            "Speed: 4.4ms preprocess, 240.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 233.8ms\n",
            "Speed: 5.0ms preprocess, 233.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 147.7ms\n",
            "Speed: 3.4ms preprocess, 147.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 142.1ms\n",
            "Speed: 4.5ms preprocess, 142.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 160.9ms\n",
            "Speed: 4.3ms preprocess, 160.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 137.3ms\n",
            "Speed: 4.2ms preprocess, 137.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 156.2ms\n",
            "Speed: 4.2ms preprocess, 156.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 134.8ms\n",
            "Speed: 4.7ms preprocess, 134.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 169.2ms\n",
            "Speed: 4.1ms preprocess, 169.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 135.3ms\n",
            "Speed: 4.3ms preprocess, 135.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 135.5ms\n",
            "Speed: 4.5ms preprocess, 135.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 136.8ms\n",
            "Speed: 4.5ms preprocess, 136.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 161.7ms\n",
            "Speed: 6.3ms preprocess, 161.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 160.8ms\n",
            "Speed: 4.5ms preprocess, 160.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 136.5ms\n",
            "Speed: 7.1ms preprocess, 136.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 137.5ms\n",
            "Speed: 4.4ms preprocess, 137.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 159.7ms\n",
            "Speed: 5.0ms preprocess, 159.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 132.3ms\n",
            "Speed: 4.4ms preprocess, 132.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 137.2ms\n",
            "Speed: 5.9ms preprocess, 137.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 142.0ms\n",
            "Speed: 4.2ms preprocess, 142.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 139.6ms\n",
            "Speed: 4.3ms preprocess, 139.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 138.1ms\n",
            "Speed: 4.5ms preprocess, 138.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 139.0ms\n",
            "Speed: 9.0ms preprocess, 139.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 137.0ms\n",
            "Speed: 4.5ms preprocess, 137.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 149.4ms\n",
            "Speed: 4.5ms preprocess, 149.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 143.8ms\n",
            "Speed: 7.3ms preprocess, 143.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 137.1ms\n",
            "Speed: 5.2ms preprocess, 137.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 138.5ms\n",
            "Speed: 4.5ms preprocess, 138.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 143.9ms\n",
            "Speed: 4.8ms preprocess, 143.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 155.6ms\n",
            "Speed: 4.3ms preprocess, 155.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 137.3ms\n",
            "Speed: 4.2ms preprocess, 137.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 144.3ms\n",
            "Speed: 4.6ms preprocess, 144.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 140.6ms\n",
            "Speed: 4.3ms preprocess, 140.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 155.1ms\n",
            "Speed: 4.3ms preprocess, 155.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 143.1ms\n",
            "Speed: 4.2ms preprocess, 143.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 144.9ms\n",
            "Speed: 4.6ms preprocess, 144.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 153.5ms\n",
            "Speed: 5.3ms preprocess, 153.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 139.8ms\n",
            "Speed: 4.8ms preprocess, 139.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 135.7ms\n",
            "Speed: 4.2ms preprocess, 135.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 143.9ms\n",
            "Speed: 4.5ms preprocess, 143.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 136.6ms\n",
            "Speed: 4.5ms preprocess, 136.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 140.1ms\n",
            "Speed: 3.7ms preprocess, 140.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 216.1ms\n",
            "Speed: 6.5ms preprocess, 216.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 204.6ms\n",
            "Speed: 11.4ms preprocess, 204.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 209.4ms\n",
            "Speed: 4.3ms preprocess, 209.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 213.8ms\n",
            "Speed: 4.3ms preprocess, 213.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 197.9ms\n",
            "Speed: 4.4ms preprocess, 197.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 227.4ms\n",
            "Speed: 4.2ms preprocess, 227.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 220.9ms\n",
            "Speed: 4.5ms preprocess, 220.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 225.6ms\n",
            "Speed: 4.1ms preprocess, 225.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 132.5ms\n",
            "Speed: 4.3ms preprocess, 132.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 161.5ms\n",
            "Speed: 4.2ms preprocess, 161.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 134.7ms\n",
            "Speed: 4.3ms preprocess, 134.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 158.0ms\n",
            "Speed: 4.3ms preprocess, 158.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 138.8ms\n",
            "Speed: 4.5ms preprocess, 138.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 142.1ms\n",
            "Speed: 5.9ms preprocess, 142.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 135.4ms\n",
            "Speed: 5.0ms preprocess, 135.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 143.5ms\n",
            "Speed: 4.6ms preprocess, 143.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 134.1ms\n",
            "Speed: 4.0ms preprocess, 134.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 138.2ms\n",
            "Speed: 4.3ms preprocess, 138.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 150.5ms\n",
            "Speed: 4.2ms preprocess, 150.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 133.9ms\n",
            "Speed: 4.3ms preprocess, 133.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 146.1ms\n",
            "Speed: 5.9ms preprocess, 146.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 141.9ms\n",
            "Speed: 4.0ms preprocess, 141.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 154.3ms\n",
            "Speed: 4.3ms preprocess, 154.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 144.3ms\n",
            "Speed: 4.2ms preprocess, 144.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 134.2ms\n",
            "Speed: 6.2ms preprocess, 134.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 141.0ms\n",
            "Speed: 4.4ms preprocess, 141.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 155.9ms\n",
            "Speed: 4.6ms preprocess, 155.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 136.5ms\n",
            "Speed: 4.1ms preprocess, 136.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 145.1ms\n",
            "Speed: 3.8ms preprocess, 145.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 136.0ms\n",
            "Speed: 4.5ms preprocess, 136.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 143.7ms\n",
            "Speed: 4.5ms preprocess, 143.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 139.3ms\n",
            "Speed: 4.6ms preprocess, 139.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 140.5ms\n",
            "Speed: 4.2ms preprocess, 140.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 137.9ms\n",
            "Speed: 5.8ms preprocess, 137.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 139.9ms\n",
            "Speed: 4.4ms preprocess, 139.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 34 persons, 154.8ms\n",
            "Speed: 4.5ms preprocess, 154.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 140.5ms\n",
            "Speed: 4.4ms preprocess, 140.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 142.6ms\n",
            "Speed: 4.7ms preprocess, 142.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 141.3ms\n",
            "Speed: 3.5ms preprocess, 141.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 156.0ms\n",
            "Speed: 4.5ms preprocess, 156.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 140.4ms\n",
            "Speed: 4.1ms preprocess, 140.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 135.1ms\n",
            "Speed: 5.8ms preprocess, 135.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 142.5ms\n",
            "Speed: 3.9ms preprocess, 142.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 137.6ms\n",
            "Speed: 4.3ms preprocess, 137.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 142.0ms\n",
            "Speed: 4.3ms preprocess, 142.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 143.8ms\n",
            "Speed: 4.7ms preprocess, 143.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 139.7ms\n",
            "Speed: 4.3ms preprocess, 139.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 143.9ms\n",
            "Speed: 4.2ms preprocess, 143.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 152.5ms\n",
            "Speed: 4.6ms preprocess, 152.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 192.3ms\n",
            "Speed: 4.3ms preprocess, 192.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 214.4ms\n",
            "Speed: 4.4ms preprocess, 214.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 222.1ms\n",
            "Speed: 4.5ms preprocess, 222.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 212.5ms\n",
            "Speed: 12.1ms preprocess, 212.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 206.3ms\n",
            "Speed: 5.8ms preprocess, 206.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 240.9ms\n",
            "Speed: 4.5ms preprocess, 240.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 216.5ms\n",
            "Speed: 9.3ms preprocess, 216.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 215.3ms\n",
            "Speed: 10.2ms preprocess, 215.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 137.2ms\n",
            "Speed: 4.5ms preprocess, 137.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 139.7ms\n",
            "Speed: 5.6ms preprocess, 139.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 138.9ms\n",
            "Speed: 4.1ms preprocess, 138.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 134.6ms\n",
            "Speed: 4.1ms preprocess, 134.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 141.6ms\n",
            "Speed: 4.1ms preprocess, 141.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 153.1ms\n",
            "Speed: 4.0ms preprocess, 153.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 134.0ms\n",
            "Speed: 4.1ms preprocess, 134.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 144.2ms\n",
            "Speed: 4.3ms preprocess, 144.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 150.7ms\n",
            "Speed: 4.5ms preprocess, 150.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 151.3ms\n",
            "Speed: 4.6ms preprocess, 151.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 133.4ms\n",
            "Speed: 5.5ms preprocess, 133.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 147.8ms\n",
            "Speed: 4.4ms preprocess, 147.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 137.5ms\n",
            "Speed: 4.3ms preprocess, 137.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 149.5ms\n",
            "Speed: 8.7ms preprocess, 149.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 30 persons, 132.7ms\n",
            "Speed: 6.3ms preprocess, 132.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 142.8ms\n",
            "Speed: 4.5ms preprocess, 142.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 135.0ms\n",
            "Speed: 4.9ms preprocess, 135.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 28 persons, 141.2ms\n",
            "Speed: 4.5ms preprocess, 141.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 176.6ms\n",
            "Speed: 6.1ms preprocess, 176.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 141.4ms\n",
            "Speed: 3.6ms preprocess, 141.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 31 persons, 137.6ms\n",
            "Speed: 4.6ms preprocess, 137.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 139.1ms\n",
            "Speed: 5.2ms preprocess, 139.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 29 persons, 160.7ms\n",
            "Speed: 4.3ms preprocess, 160.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 139.5ms\n",
            "Speed: 4.4ms preprocess, 139.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 33 persons, 135.7ms\n",
            "Speed: 5.5ms preprocess, 135.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 32 persons, 148.3ms\n",
            "Speed: 4.2ms preprocess, 148.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Release video resources\n"
      ],
      "metadata": {
        "id": "dx9VQOx9KYR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap.release()\n",
        "out.release()\n"
      ],
      "metadata": {
        "id": "53Sny0MMGIGv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate & save improved heatmap\n"
      ],
      "metadata": {
        "id": "aYEg2W-8Kd3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heatmap = np.zeros((height, width), dtype=np.float32)\n",
        "for track_id in track_history:\n",
        "    for center_x, center_y in track_history[track_id]:\n",
        "        if 0 <= center_y < height and 0 <= center_x < width:\n",
        "            heatmap[int(center_y), int(center_x)] += 1"
      ],
      "metadata": {
        "id": "RDgr0GsPGIJz"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gaussian blur for smoothing\n"
      ],
      "metadata": {
        "id": "w2iPMpYmKq9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heatmap = cv2.GaussianBlur(heatmap, (21, 21), 10)\n",
        "\n",
        "# Normalize heatmap\n",
        "heatmap = np.clip(heatmap, 0, None)\n",
        "if heatmap.max() > 0:\n",
        "    heatmap = heatmap / heatmap.max()"
      ],
      "metadata": {
        "id": "DOvHDEvUnFkQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize and save heatmap\n"
      ],
      "metadata": {
        "id": "H9oCOFIPKv2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(heatmap, cmap='hot', interpolation='bilinear', vmin=0, vmax=0.8)\n",
        "plt.colorbar(label='Intensity')\n",
        "plt.title('People Movement Heatmap')\n",
        "plt.axis('off')\n",
        "plt.savefig('heatmap.png', bbox_inches='tight', pad_inches=0)\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "NMNNSD_3b1wY"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VWdI7M7Hdqpc"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}